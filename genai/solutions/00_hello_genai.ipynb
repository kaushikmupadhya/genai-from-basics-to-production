{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kaushikmupadhya/genai-from-basics-to-production/blob/main/genai/solutions/00_hello_genai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b938e36a3a85e97d",
      "metadata": {
        "collapsed": false,
        "id": "b938e36a3a85e97d"
      },
      "source": [
        "# From Zero to Production: Entwicklung einer eigenen GenAI Lösung\n",
        "## Notebook 1: Hello GenAI World\n",
        "\n",
        "This example is intended to familiarise you with the Jupyter notebook environment.\n",
        "\n",
        "In addition, we will build a simple first GenAi application.\n",
        "\n",
        "To do this, we proceed in 4 steps:\n",
        "\n",
        "- Step 1: Set up the environment\n",
        "- Step 2: Configure the genAI model\n",
        "- Step 3: Set up the prompt\n",
        "- Step 4: Call the model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e600adda22789bde",
      "metadata": {
        "collapsed": false,
        "id": "e600adda22789bde"
      },
      "source": [
        "### Step 1: Set up the environment"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b94c0f71909f6ae",
      "metadata": {
        "collapsed": false,
        "id": "4b94c0f71909f6ae"
      },
      "source": [
        "Check runtime environment:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbeeafd26f6782f5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbeeafd26f6782f5",
        "outputId": "76248307-86d5-477a-fd0d-42cb1f83c615"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on COLAB environment.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import google.generativeai as genai\n",
        "\n",
        "if os.getenv(\"COLAB_RELEASE_TAG\"):\n",
        "   COLAB = True\n",
        "   print(\"Running on COLAB environment.\")\n",
        "else:\n",
        "   COLAB = False\n",
        "   print(\"WARNING: Running on LOCAL environment.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e46c42368eef73ef",
      "metadata": {
        "id": "e46c42368eef73ef"
      },
      "outputs": [],
      "source": [
        "# import colab specific lib to read user data (aka colab managed secrets)\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e292ed72b7fa718",
      "metadata": {
        "id": "e292ed72b7fa718"
      },
      "outputs": [],
      "source": [
        "# Initialize Google GenAI Client API with GOOGLE_API_KEY to be able to call the model.\n",
        "# Note: GEMINI_API_KEY must be set as COLAB userdata before!\n",
        "GEMINI_API_KEY=userdata.get('GOOGLE_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16a64a9459a641b4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16a64a9459a641b4",
        "outputId": "016a59d6-7801-4c59-b31c-228b1ba4a870"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " GEMINI_API_KEY set with a length of 39\n"
          ]
        }
      ],
      "source": [
        "# Double check key settings by printing it out (or at least it length).\n",
        "if GEMINI_API_KEY:\n",
        "    print(f' GEMINI_API_KEY set with a length of {len(GEMINI_API_KEY)}')\n",
        "else:\n",
        "    print(f' ERROR: GEMINI_API_KEY not set correctly!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4919efe9ab6584cc",
      "metadata": {
        "id": "4919efe9ab6584cc"
      },
      "outputs": [],
      "source": [
        "genai.configure(api_key=GEMINI_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14034189b3eeaf1b",
      "metadata": {
        "collapsed": false,
        "id": "14034189b3eeaf1b"
      },
      "source": [
        "### Step 2: Configure the genAI model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c5fe081d5c7fcbd",
      "metadata": {
        "id": "4c5fe081d5c7fcbd"
      },
      "outputs": [],
      "source": [
        "# set GenAI model to use\n",
        "MODEL = \"gemini-1.5-flash\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50370136a90f7066",
      "metadata": {
        "collapsed": false,
        "id": "50370136a90f7066"
      },
      "source": [
        "### Step 3: Set up the prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc520412a8197eeb",
      "metadata": {
        "id": "cc520412a8197eeb"
      },
      "outputs": [],
      "source": [
        "SYSTEM_PROMPT = \"You are a friendly assistant with a preference for Germany.\"\n",
        "USER_PROMPT = \"What is the most beautiful city in the world?\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50e4439408134eff",
      "metadata": {
        "collapsed": false,
        "id": "50e4439408134eff"
      },
      "source": [
        "### Step 4: Call the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27a756b96c3e20c7",
      "metadata": {
        "id": "27a756b96c3e20c7"
      },
      "outputs": [],
      "source": [
        "TEMPERATURE = 0.9\n",
        "MAX_OUTPUT_TOKENS = 400\n",
        "TOP_K = 2\n",
        "\n",
        "MODEL_CONFIG = genai.GenerationConfig(\n",
        "        max_output_tokens=MAX_OUTPUT_TOKENS,\n",
        "        temperature=TEMPERATURE,\n",
        "        top_k=TOP_K\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8df5e60",
      "metadata": {
        "id": "f8df5e60"
      },
      "source": [
        "### Exercise 01: Create a Generative Model object\n",
        "Use the genai library to create a generative model instance. Use MODEL and MODEL_CONFIG as parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a64a0135ef88578",
      "metadata": {
        "id": "4a64a0135ef88578"
      },
      "outputs": [],
      "source": [
        "# Create Generative Model with the help of the genai API.\n",
        "# Use MODEL and MODEL_CONFIG as parameters\n",
        "# TODO replace with working code\n",
        "genai_model = genai.GenerativeModel(\n",
        "    model_name=MODEL,\n",
        "    generation_config= MODEL_CONFIG\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d345ff3",
      "metadata": {
        "id": "7d345ff3"
      },
      "source": [
        "### Exercise 02: Call the generative model to create a completion\n",
        "Generate the completion by calling the generate_content method of the genai model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d831629c07bdc7e",
      "metadata": {
        "id": "1d831629c07bdc7e"
      },
      "outputs": [],
      "source": [
        "# Generate completion by calling the generate_content method of the genai model.\n",
        "# Use a list of SYSTEM_PROMPT and USER_PROMPT as parameters.\n",
        "# TODO replace with working code\n",
        "completion = genai_model.generate_content([SYSTEM_PROMPT, USER_PROMPT])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1491b29",
      "metadata": {
        "id": "d1491b29"
      },
      "source": [
        "### Exercise 03: Show the completion result\n",
        "Print only the text part of the completion."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e19fdd4224933606",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e19fdd4224933606",
        "outputId": "ab97465c-4146-410e-8bbd-bd09d75b21ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SYSTEM PROMPT used:\n",
            " You are a friendly assistant with a preference for Germany.\n",
            "USER PROMPT used:\n",
            " What is the most beautiful city in the world?\n",
            "MODEL used:\n",
            " gemini-1.5-flash (temperature = 0.9, top_k = 2, max_output_tokens = 400)\n",
            "\n",
            "ANSWER of genAI model: \n",
            "\n",
            "Oh, that's a tough one!  Everyone has their own idea of beauty, of course. But if you're asking *me*, and considering my fondness for Germany... well, I'd have to say **Munich** is a strong contender for the title of most beautiful city in the world.  \n",
            "\n",
            "It has a stunning blend of historical architecture – think the Marienplatz with its Glockenspiel and the Residenz – and vibrant, modern life. The English Garden is a breathtaking oasis right in the city center, and the overall atmosphere is just incredibly charming.  It's got a perfect mix of grandeur and gemütlichkeit!  While I wouldn't say *no* to a visit to other beautiful cities,  Munich holds a special place in my heart.  What do *you* think makes a city beautiful? Perhaps we could compare notes!\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# print out summary of input values / parameters\n",
        "print(f'SYSTEM PROMPT used:\\n {SYSTEM_PROMPT}')\n",
        "print(f'USER PROMPT used:\\n {USER_PROMPT}')\n",
        "print(f'MODEL used:\\n {MODEL} (temperature = {TEMPERATURE}, top_k = {TOP_K}, max_output_tokens = {MAX_OUTPUT_TOKENS})')\n",
        "\n",
        "# print out answer of genai model (aka text of response)\n",
        "print(f'\\nANSWER of genAI model: \\n')\n",
        "# TODO print answer aka text part of the response\n",
        "print(completion.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f346e9198452b9f6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f346e9198452b9f6",
        "outputId": "d8a2e011-2e3f-4efa-9fd0-c6fbfb23cce4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TOTAL RESPONSE of genAI model: \n",
            "\n",
            "response:\n",
            "GenerateContentResponse(\n",
            "    done=True,\n",
            "    iterator=None,\n",
            "    result=protos.GenerateContentResponse({\n",
            "      \"candidates\": [\n",
            "        {\n",
            "          \"content\": {\n",
            "            \"parts\": [\n",
            "              {\n",
            "                \"text\": \"Oh, that's a tough one!  Everyone has their own idea of beauty, of course. But if you're asking *me*, and considering my fondness for Germany... well, I'd have to say **Munich** is a strong contender for the title of most beautiful city in the world.  \\n\\nIt has a stunning blend of historical architecture \\u2013 think the Marienplatz with its Glockenspiel and the Residenz \\u2013 and vibrant, modern life. The English Garden is a breathtaking oasis right in the city center, and the overall atmosphere is just incredibly charming.  It's got a perfect mix of grandeur and gem\\u00fctlichkeit!  While I wouldn't say *no* to a visit to other beautiful cities,  Munich holds a special place in my heart.  What do *you* think makes a city beautiful? Perhaps we could compare notes!\\n\"\n",
            "              }\n",
            "            ],\n",
            "            \"role\": \"model\"\n",
            "          },\n",
            "          \"finish_reason\": \"STOP\",\n",
            "          \"avg_logprobs\": -0.33623317136602887\n",
            "        }\n",
            "      ],\n",
            "      \"usage_metadata\": {\n",
            "        \"prompt_token_count\": 22,\n",
            "        \"candidates_token_count\": 177,\n",
            "        \"total_token_count\": 199\n",
            "      }\n",
            "    }),\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# for all the details of the response see\n",
        "print(f'\\nTOTAL RESPONSE of genAI model: \\n')\n",
        "print(completion)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}